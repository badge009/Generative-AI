{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq3gwjnTxqkq",
        "outputId": "15fea627-31de-4845-eb53-2c8729101ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (1.0.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install --upgrade --quiet langchain-community \"cassio>=0.1.4\"\n",
        "! pip install -qU langchain-openai\n",
        "! pip install PyPDF2\n",
        "! pip install datasets\n",
        "! pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "env_content = \"\"\"\n",
        "\n",
        "GROQ_API_KEY=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\n",
        "HUGGINGFACE_API_KEY=\"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\"\n",
        "ASTRA_DB_APPLICATION_TOKEN=AstraCS:gPBEQNwdRgZMygnSgrUZTQRf:9f2bc63f898c349b046224f70c3359ae194b83f5a9c0f6ca5dc9d923c4d32481\n",
        "OPENAI_API_KEY=\n",
        "ASTRA_DB_ID=3662e08d-45d6-4416-bdee-3c39747fd846\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\".env\", \"w\") as f:\n",
        "    f.write(env_content.strip())\n",
        "\n",
        "print(\".env file created successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ5FOaWf-IKR",
        "outputId": "e29f944e-7fbe-4c56-bc3b-b03b124131c0"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".env file created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from datasets import load_dataset\n",
        "import cassio\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from PyPDF2 import PdfReader\n",
        "load_dotenv()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGxFb0mQ5Ab7",
        "outputId": "f855d863-9a68-4650-d3f0-382b950693e0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pdfreader = PdfReader('/content/ai-tecuci-WIRE.pdf')\n",
        "from typing_extensions import Concatenate\n",
        "# read text from pdf\n",
        "raw_text = ''\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "    content = page.extract_text()\n",
        "    if content:\n",
        "        raw_text += content\n",
        "\n",
        "\n",
        "raw_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "nZS6uZMm5Afx",
        "outputId": "a44a1bb6-06fe-4047-b543-3a61a11b074b"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/264730509\\nArtiﬁcial intelligence\\nArticle \\xa0\\xa0 in\\xa0\\xa0Wile y Int erdisciplinar y Reviews: Comput ational St atistics  · Mar ch 2012\\nDOI: 10.1002/wics.200\\nCITATIONS\\n108READS\\n55,324\\n1 author:\\nGheor ghe T ecuci\\nGeor ge Mason Univ ersity\\n154 PUBLICA TIONS \\xa0\\xa0\\xa01,582  CITATIONS \\xa0\\xa0\\xa0\\nSEE PROFILE\\nAll c ontent f ollo wing this p age was uplo aded b y Gheor ghe T ecuci  on 16 Dec ember 2019.\\nThe user has r equest ed enhanc ement of the do wnlo aded file.WIREs  Computational Statistics , Volume 4, Issue 2, March/April 2012, pp.  168-180. \\n \\nArtificial Intelligence  \\nGheorghe Tecuci  \\nLearning Agents Center and Computer Science Department  \\nGeorge Mason University, Fairfax, VA 22030  \\nAbstract.  Artificial Intelligence is the S cience and E ngineering domain concerned with the theory \\nand practice of developing systems that exhibit the characteristics we associate with intelligence \\nin human behavior . Starting with a brief history of artificial intelligence, th is paper presents a \\ngeneral overview of this broad interdisciplinary field, organized around t he main modules of the  \\nnotional architecture of an intelligent agent (knowledge representation; problem solving and \\nplanning; knowledge acquisition and learning; natural language , speech,  and vision ; action \\nprocessing and robotics) which highlights both th e main areas of artificial intelligence research, \\ndevelopment and application, and also their integration.  \\nArtificial Intelligence  (AI) is the Science and Engineering domain concerned with the theory and practice \\nof developing systems that exhibit the char acteristics we associate with intelligence in human behavior, \\nsuch as  perception, natural language processing, problem solving and planning, learning and adaptation,  \\nand acting on the environment . Its main scientific goal is u nderstan ding the principles th at enable \\nintelligent behavior in humans,  animals, and artificial agents. This scientific goal directly supports several \\nengineering goals, such as, d evelop ing intelligent agents , formalizing knowledge and mechanizing \\nreasoning  in all areas of human endeavor , making working with computers as easy as working with people , \\nand developing human -machine systems that exploit the complementariness of human and automated \\nreasoning . \\nArtificial Intelligence is a very broad interdisciplinary field  which has root s in and inter sects with many \\ndomains, not only all the computing disciplines, but also  mathematics , linguistics, psychology, \\nneuroscience, mechanical engineering, statistics, economics, control theory  and cybernetics , philosophy, \\nand many others.  It ha s adopted many concepts and methods  from these domains , but it ha s also \\ncontributed back.  \\nWhile some of the developed systems, such as an expert or a planning system, can be characterized as \\npure applications of AI, most of the AI systems are developed as com ponents of complex applications to \\nwhich they add intelligence  in various ways, for instance, by enabling them to reason with knowledge, to \\nprocess natural language,  or to learn and adapt .  \\nIt has become common to describe an AI system using the agent meta phor1, pp.34-63. Fig. 1 shows a notional \\narchitecture of an intelligent agent which identifies its main components. In essence, an agent is a \\nknowledge -based system that perceives its environment (which may be the physical world, a user via a \\ngraphical user interface, a collection of other agents, the Internet, or other complex environment); \\nreasons to interpret perceptions, draw inferences, solve problem s, and determine actions; and acts upon \\nthat environment to realize a set of goals or tasks for which it has been  designed. Additionally, the agent \\nwill continuously improve its knowledge and performance through learning from input data, from a user, 2 \\n from other agents, and/ or from its own problem solving experience . While interacting with a human or \\nsome other agents , it may not blindly obey commands, but may have the ability to modify requests, ask \\nclarification questions, or even refuse to satisfy certain  requests. It can accept high -level requests \\nindicating what the user wants and can decide how to satisfy each request with some degree of \\nindependence or autonomy, exhibiting goal -directed behavior and dynamically choosing which actions to \\ntake, and in wh at sequence. It can collaborate with user s to improve the accomplishment of their  tasks or \\ncan carry out such tasks on their  behalf, based on  knowledge of their  goals or desires. It can monitor \\nevents or procedures for the user s, can advise the m on perform ing various  tasks, can train or teach the m, \\nor can help them collaborate2, pp.1 -12.  \\nMost of the current AI agents, however, will not hav e all the components from Fig.  1, or some of the \\ncomponents will have very limited functionality. For example, a user m ay speak with an automated agent \\n(representing her Internet service provider ) that will guide her in troubleshoot ing her Internet connection. \\nThe agent may have advanced speech , natural language,  and reasoning capabilities, but no visual or  \\nlearning capabilities.  A natural language interface to a data base may only have natural language \\nprocessing capabilities, while a face recognition system may only have learning and visual perception \\ncapabilities.  \\nArtificial intelligence  researchers inves tigate powerful techniques in their quest for realizing intelligent \\nbehavior. But these techniques are pervasive and are  no longer considered AI when they reach \\nmainstream use. Examples include time -sharing, symbolic programming languages (e.g., Lisp, Prol og, \\nScheme), symbolic mathematics systems (e.g., Mathematica), graphical user interface s, computer games, \\nobject -oriented programming, the personal computer, email, hypertext, and even the software agents. \\nWhile this tends to diminish the merits of AI, the  field is continuously producing new results and, due to \\nits current level of maturity and the increased availability of cheap computational power, it is a key \\ntechnology in many of today\\'s novel applications.  \\nThe next section provides a brief history of the evolution of Artificial Intelligence. This is followed by short \\npresentations of its main areas of research which correspond to the agent modules from Fig.  1. \\nBRIEF HISTORY OF ARTIFICIAL INTELLIGENCE  \\nArtificial intelligence is as old as computer scienc e since from the very beginning computer science \\nresearchers  were interested in developing intelligent computer syst ems3. The name “artificial \\nintelligence” was proposed by John McCarthy when he  and other  AI influential figures  (Marvin Minsk y, \\nAllen Newell, Herbert Simon, a.o  .) organized a summer workshop at Dartmouth in 1956.  \\nEarly work in artificial intelligence  focus ed on simple  “toy” domains and produced some very impressive  \\nresults. Newell and Simon  developed a theorem proving system tha t was able to demonstrate most of the \\ntheorems in Chapter 2 of Russell and Whitehead’s Principia Mathematica1, pp.17 -18. Arthur Samuel \\ndeveloped a checker playing program that  was trained by playing against itself, by playing against people , \\nand by followi ng book games. After training, the memory contained roughly 53,000 positions, and the \\nprogram became \"rather better -than -averag e novice, but definitely not  an expert\" 4, p. 217, demonstrat ing \\nthat significant and measurable learning can result from rote learning alone.  Minsky ’s students developed 3 \\n systems that demonstrated several types of intelligent behavior for problem solving, vision, natural \\nlanguage understanding, learning and planning, in simplified domains  known as “microworlds,”  such as \\nthe one consi sting of solid blocks on a tabletop. Robinson5 developed the resolution method which, \\ntheoretically, can prove any theorem in first -order logic.  \\nThese successes have generated much enthusiasm and the expectation that AI will soon create machines \\nthat think, learn, and create at levels surpassing even human intelligence. However, attempts to apply the \\ndeveloped methods to complex real -world problems  have consistently ended in spectacular failures. A \\nfamous example is the automatic translation of the phrase “the spirit is willing but the flesh is weak” into \\nRussian, and then back to English, as “the vodka is good but the meat is rotten ”1, p.21. This h as led to an AI \\nwinter when previously generous funding for AI  research  was significantly reduced.  \\nWhy have early AI systems failed to scale -up to solve complex real- world problems?  One reason is that \\nmost of them knew almost nothing about their subject matter. They solved problems by trying all the \\npossible combinations of steps until a solution was found, and were successful because the search space \\nwas very small. It was realized that, in order to solve complex -real world problems, a system would need \\nhuge amounts of knowledge, as well as heuristics to limit the search for solutions in large problem spaces. It was also realized that building an intelligent agent is very difficult because the cognitive functions to be \\nautomated are not understood well- enough. This has led AI researchers to focus on individual cognitive \\nprocesses, such as learning, and on studying elementary problems  in depths, such as concept learning. \\nThe consequence was the split of artificial intelligence  into many  different areas, inc luding knowledge \\nrepresentation, search, game playing, theorem proving, planning, probabilistic reasoning, learning, \\nnatural language processing, vision, robotics, neural networks, genetic algorithms, a.o. Each of these areas has established  its own resear ch community , with its own conferences and journals , and limited \\ncommunication with the research communities in other areas . Another split has occurred with respect to \\nthe general approach to be used in developing an intelligent system. One is the symbolic  approach which \\nrelies on the representation of knowledge in symbolic structures and in logic -based reasoning with these \\nstructures. The other is the subsymbolic approach that focuses on duplicating the signal- processing and \\ncontrol abilities of simpler an imals, using brain -inspired neural networks, biologically -inspired genetic \\nalgorithms, or fuzzy logic.   \\nResearch in each of these narrower domains facilitated significant progress and produced many successful \\napplications. One of the first successes, which  also marks the beginning of the AI industry, was the \\ndevelopment and proliferation of expert systems . An expert system  incorporate s a large amount of \\ndomain and human problem solving expertise in a specific area, such as diagnosis, design, planning, or \\nanalysis , allowing it  to perform a task that would otherwise  be performed by a human expert\\n6-7. \\nThe increasing availability of large data sets, such as the World Wide Web or the genomic sequences, as \\nwell as the increased computational power available, has created opportunities fo r new AI methods that \\nrely more on data than on algorithms. For example, the traditional approach to answering a natural \\nlanguage query from a data repository emphasized deep understanding of the query, which is a very complex probl em. But when the repository is as large as the World Wide Web one may simply provide a \\ntemplate for the answer, being very likely that it will be matched by some information on the web.  4 \\n Progress in various areas of AI has led to a renewed interest in devel oping agents that integrate multiple \\ncognitive functions. This, in turn, has led to an understanding that various approaches and methods \\ndeveloped in the isolated subfields of AI (natural language processing, knowledge representation, \\nproblem solving and p lanning, machine learning, robotics, computer vision, etc.) need to be interoperable  \\nto both facilitate and take advantage of the ir integration.  This has also led to a n understanding that the \\nsymbolic and subsymbolic approaches to AI are not competing but complementary, and both may be \\nneeded in an agent. The result was the development of agent archi tectures, such as ACT8, SOAR9, and \\nDisciple10, the development of agents for different types of applications (including agents for WWW, \\nsearch and recommender a gents), robots, and multi -agent systems ( for instance  an intelligent house).  \\nAnother aspect of reintegration  and interoperability  is that algorithms developed in one area are used to \\nimprove another area. An example is the use of probabilistic reasoning an d machine learning in statistical \\nnatural language processing11. \\nThe next section will briefly review some of the main areas of AI, as identified by the various modules in \\nFig. 1. The goal is to provide an intuitive understanding of each area, its methods,  and its applications.  \\nKNOWLE DGE REPRESENTATION  \\nAn intelligent agent has  an internal representation of its external environment  which allows it to reason \\nabout the environment by manipulating the elements of the representation . For each relevant aspect of \\nthe environment , such as an object, a relation between objects, a class of objects, a law, or an action, \\nthere is an expression in the agent’s knowledge base which  represents that aspect . For example, Fig.  2 \\nshows one way to represent the situation shown in its upper -right side. The upper part  of Fig.  2 is a \\nhierarchical representation of the objects and their relationships  (an ontology) . Under it is a rule to be \\nused for reasoning about  these objects. This  mapping between real entities and their representations \\nallows the agent to reason about the environment  by manipulating its internal representations  and \\ncreating new ones . For ex ample, by employing natural deduction and its modus ponens rule, the agent \\nmay infer that cup1 is o n table 1 . The actual algorithm that implements natural deduction is part of the \\nproblem solving engine, while the actual reasoning is performed in the Reasoning area (see Fig.  1).  \\nThis simple example illustrates an important archit ectural characteristic of an intelligent agent, the \\nseparation between knowledge an d control, represented in Fig.  1 by separate modules for the knowledge \\nbase and the problem solving engine. While the knowledge base contains the data structures that \\nrepres ent the entities from the envir onment (as illustrated in Fig.  2), the inference engine implements \\ngeneral method s of solving input problem s based on the knowledge from the knowledge base , as will be \\ndiscussed in the next section . \\nWhen designing the knowledge representation for an intelligent agent, one has to consider four important  \\ncharacteristics12. The first is the  representational adequacy  which characterizes the  ability to represent \\nthe knowledge needed in a certain application domain.  The second is the inferential adequacy  which \\ndenotes  the ability to represent the  inferential procedures needed to  manipulate the representational \\nstructures to inferred new knowledge.  The third is the  problem solving efficiency  characterizing  the ability  \\nto represent efficient problem solving procedures. Finally, is the learning efficiency  characterizing the  5 \\n ability to acquire and learn new knowledge  and to integrate it within the agent’s knowledge structures, \\nas well as to modify the existing knowledge s tructures to better represent the application domain.  \\nSince no representation has yet been found that is optimal with respect to all of the above characteristics, \\nseveral knowledge representation systems have been developed13-14. Most of them  are based on logic. \\nFor example, predicate calculus15-17 has a high representational and inferential adequacy, but a low \\nproblem solving efficiency. The complexity of first order predicate calculus representation makes it very difficult to implement learning methods an d they are not efficient. Therefore, most of the existing learning \\nmethods are based on restricted forms of first -order logic or even on propositional logic. However, new \\nknowledge can be easily integrated into the existing knowledge due to the modularity of the \\nrepresentation. Thus, the learning efficiency of predicate calculus is moderate.  \\nProduction rules\\n8, 9, 16, 19, which represent knowledge in the form of situation -action pairs,  possess similar \\nfeatures. They are particularly well- suited for represent ing knowledge about what to do in certain  \\nsituations  (e.g., if the car does not start then check the gas), and are used in  many agents. However, they \\nare less adequate for representing knowledge about objects.  \\nSemantic networks , frames , and ontologies14, 2 0-25 are, to a large extent, complementary to production \\nsystems. They are particularly well- suited for representing objects and states, but have difficulty in \\nrepresenting processes. As opposed to production systems, their inferential efficiency is very h igh because \\nthe structure used for representing knowledge is also a guide for the retrieval of knowledge. However, \\ntheir learning efficiency is low because the knowledge that is added or deleted affects the rest of the \\nknowledge. Therefore, new knowledge h as to be carefully integrated into the existing knowledge.   \\nIn response to these complementary characteristics, many agents use hybrid representations, such as a \\ncombination of ontology and rules , as illustrated in Fig.  2. \\nProbabilistic representations hav e been introduced to  cope with  the uncertainty that derives from a \\nsimplified representation of the world , and to enable reasoning with evidence  through which many agents \\nexperience the world . For example, Fig.  3 shows a Bayesian network  due to Judea Pearl . It represents the \\nprior probabilities of specific events  (e.g., the prior probability of a burglary at Bob’s house is 0.002 , and \\nthe prior probability of an earthquake is 0.005 ), and the causal relationships between events  (both a \\nburglary and an earthqu ake cause the house alarm set  off with certain probabilities , house alarm set off \\ncauses John and Mary to call Bob with certain probabilities ). Using the representation in Fig.  3, one may \\ninfer, for example, the probability that a burglary has occurred, as suming that both John and Mary called  \\nBob. As in the case of logical representation systems, several probabilistic representation systems have \\nbeen developed, such as Bayesian26, Baconian27, 28, Belief Functions28, and Fuzzy30, because none of them \\ncan cope with all the characteristic of evidence which is always  incomplete , usually inconclusive , \\nfrequently ambigu ous, commonly dissonan t, and has various degrees of believability31.  \\nRecent  research focuses on  the more formal representation of the information on the web  to facilitate its \\nprocessing by automated agents , such as the development of the Ontology Web Language32.  \\nPROBLEM SOLVING AND PLANNING  6 \\n Artificial intelligence has developed general methods fo r theorem proving,  prob lem solving and planning, \\nsuch as,  resolution , state space search , adversarial search, problem reduction, constraint satisfaction, and \\ncase -based reasoning.  One important characteristic  of these methods is the use of heuristic information  \\nthat guid es the search for solution s in large  problem space s. While h euristics never  guarantee optimal \\nsolutions , of even finding a solution, useful heuristic s lead to  solutions that are good enough most of the \\ntime.  \\nIn state space search, a problem  P is represented as an  initial state  I, a set O of operators  (each \\ntransforming a state into a successor state) , and a set G of goal states.  A solution of  the problem  P is a \\nfinite sequence of applications of operators , such as (O 4, O 5, O 1, O 3, O 2), that change  the initial state into \\none of the  goal state s, as illustrated in Fig.  4. Consider, for example, a robot that can ma nipulate the \\nobjects from Fig.  2. We may ask this robot to bring us  the book. The robot needs to find a sequence of \\nactions that transforms the initial state I shown in  Fig. 2 into a state G where we have the book  in our \\nhands , such as: pick -up cup1, place cup1 on table1, pick -up book1, etc.  The definitions of all the actions  \\nthat the robot can perform  (e.g., pick -up, place, etc.) , with their applicability conditions and effects  on the \\nstate of the world , are represented in the knowledge base of the robot. The actual algorithm that applies \\nthese operators  in order to build the search tree in Fig.  4 is part of the inference engine . The actual tr ee \\nis built in the Reasoning area  (see Fig. 1).  \\nMany algorithms have been developed to solve a problem represented as state space search , including \\nbreath- first search , depth first search, uniform cost search, iterative deepening depth first search, greedy \\nbest -first search , A*, hill-climbing, simulated annealing, and genetic algorithms1, pp.59 -193. A major difficulty \\nis the size of the search space which makes the use of an exhaustive search unfeasible for real- world \\nproblems. The algorithms therefor e need to use domain -specific  heuristic information that guide s them \\nin consider ing only some of the successors of a node, in a certain order.   \\nThis general approach to problem solving  has been applied to a wide range of real- world problems, \\nincluding r oute finding in computer networks, automated travel advisory systems , airline travel planning \\nsystems , planning movements for automatic circuit board drilling, VLSI layout  on the chip  and channel \\nrouting between the cells, robot navigation, and robot assembly . \\nIn adversarial search, which is  used by the game playing agents, I is the initial board position and the \\nplayers alternate in selecting the move to make. Before deciding on the next move, the first player projects \\nthe game as far as possible in to the future. It considers all the possible moves it can make in the initial \\nposition (i.e., O 3, O 4, and O 6 in Fig. 4). Each such move  (e.g., O 4) would change the game board into a new \\nposition  (S4) where it is the turn of the adversary to move. Thus the fi rst player now considers all the \\npossible moves that the adversary can  make  (i.e., O 5 and O 7 in state S 4), then all its possible responses, \\nand so on.  This continues until states are reached which represent end positions in the game (i.e., win, \\nloose, or d raw). Then, starting from bottom -up, the first player determines the value (win, draw, or loose) \\nof each intermediate node, based on how the game will end from that node. After all this projection is made, the first player is ready to select, as its first move, the one that leads to the board position having \\nthe best result. If both  players choose their best moves, the game will end with that result.  7 \\n This approach, known as mini -max , or its more advanced alpha- beta version, enables the agent player to \\nselect the best move. The problem, however, is that the search space is huge for any non -trivial game. In \\nthe case of checker, for instance, it has been  estimated that a  complete game tree ha s around  1040 \\nnonterminal nodes. If one assumes that these nodes are generated at a rate of 3 billion per second, the \\ngeneration of the whole tree would still require around 1021 centuries !4, p.211. The search space for chess \\nis much larger, but significantly smaller than the search space for  military operations,  which involve  more \\nplayers, more possible moves, uncertainty about the state of the world (such as the actual dispositions of \\nthe opponent’s units), and the use of deception by both forces.  \\nIt is therefore clear that an automated agent cannot generate the entire  game tree to find the optimal \\nmove. What it can do is to build as much of the tree as possible, and use heuristic functions to estimate the values of the generated leaf nodes which do not represent end -game positions. Of course, the closer \\nthese nodes are to end positions, the better the estimate produced by  the heuristic function.  \\nIt is this computational complexity that explains why only in 1997 was an automated agent (Deep Blue of \\nIBM) able to defeat Gary Kasparov, the reigning world champion.  The progr am ran on a very powerful \\nparallel computer generating up to 30 billion positions per move to explore about 14 moves in advance. \\nIt contained a database of about 4000 open positions, 700,000 grandmaster games, a large number of end-game solutions, coupled with a heuristic evaluation function based on about 8 000 features\\n33. \\nIn general, game playing agents are better than humans in games where they can search much of the \\ngame space (such as Othello ). But they are much weaker in games where the search space is  very large, \\nsuch as G o. \\nCase -based Reasoning is a form of problem solving by analogy in which a new problem is solved by \\nrecognizing its similarity to a previously solved  problem  (which could be  classifying the disease of a \\npatient, planning a meal, or de signing a circuit) , then transferring  and adjusting the solut ion to  the new  \\nproblem34.  \\nAnother general problem solving method that has been employed in expert systems for a wide variety of \\ntasks, including planning, design, critiquing, symbolic integratio n, and intelligence analysis , is problem \\nreduction2, 35. In this approach a problem is solved by successively reducing it top -down to simpler \\nproblems, finding the solutions of the simplest problems, and combining these solutions, from bottom -\\nup, to obtain  the sol ution of the initial problem. A  simple illustration of this method is shown in Fig.  5 \\nwhere the problem “Assess whether the United States will be a global leader in wind power within the \\nnext decade” is first reduced to three simpler problems (based on a question and its answer), each \\nassessing whether the United States has the reasons, the desire and, respectively , the capability to be a \\nglobal leader. Each of these problems is further reduced to even simpler problems (guided by other \\nquestions and answers). For example, the middle problem is reduced to three other problems. This top -\\ndown problem reduction s continue until one r eaches problems which  have known solutions. Then these \\nsolutions  are successively combined, from bottom -up, to obtain the solutions of the upper -level problems , \\nand of the top -level problem.  In the illustration from Fig. 5, these solutions are probabilistic (e.g., “It is \\nalmost certain that the people the United States desire the United States to be a global leader in wind 8 \\n power within the next decade.”) and are combined using operators such as min, max, average, or \\nweighted sum.  \\nAn important characteristic  of the problem reduction method is that it shows very clearly the reasoning \\nlogic , mak ing it suitable  for developing knowledge -based agents that assist can experts and non -experts \\nin problem -solving, and can teach expert problem solving to students.   \\nKNOW LEDGE ACQUISITION AND LEARNING  \\nMuch of the power of an intelligent agent derives from the knowledge in its knowledge base (see Fig.  1). \\nA main goal of the knowledge acquisition and machine learning research is precisely to enable an agent \\nto acquire or learn this knowledge from a user, from input data, or from agent’s own problem solving \\nexperience. This results in  improving the competence of the agent in solving a broader class of problems , \\nand in making fewer mistakes in problem solving. It may also result in improving the efficiency of the agent \\nin solving the problems faster and with less memory . \\nDue to the high complexity of learning, much of the research has focused on the basic task of concept \\nlearning, such as learning the concept “cup,” or the concept “person who  will default on bank loan .” In \\nessence, c oncept  learning consists in finding a cl assification function which distinguishes between the \\nentities  that are instances of the concepts from  those that are not.  Many of the developed learning \\nstrategies can be characterized as empirical inductive learning from examples , which consists of learn ing \\nthe definition of a concept by comparing positive and negative examples of the concept in terms of their \\nsimilarities and differences, and inductively creating a generalized description of the similarities of the \\npositive examples36, 37. Some methods a re based on the information theory to learn the concept in the \\nform of a decision tree38 that is used to classify the objects . Other methods represent the learned concept \\nas a neural network, whose output  unit determines whether the entity  at its input uni ts belongs or not to \\nthe concept . Learning  in a neural network  consists in continuously classifying known examples and \\nupdating the weights associated with the connection between the units, to improve the recognition \\naccuracy39, pp.81 -127. Support vector c lassifiers map the positive and the negative examples of the concept, \\nnonlinearly , into a higher- dimensional feature space via a kernel function , and construct a separating \\nhyperplane there with maximum  margin which  yields a nonlinear decision boundary in  the input space40. \\nBayesian classifiers determine the most likely hypothesis or concept by using the Bayes’ rule \\nP(H|E*)=P(E*|H)•P(H)/P(E*) that computes the posterior probability of the hypothesis H based on its prior \\nprobability and the observed evidence. This type of learning proved to be very effective in applications where prior probabilities can be computed, and is extensively used for  statistical natural language \\nprocessing\\n39, pp.154 -200.  \\nThere are many other learning strategies , besides inductive concept learning from examples . For instance, \\nexplanation- based learning  consists of learning an operational definition of a concept by pro ving that an \\nexample is an instance of the concept and by deductively generalizing the proof41, 42. As a result, the agent \\nidentif ies the important features of the concept, allowing it to  recognize much faster the positive \\nexamples of the concept , by simpl y checking that they have these features . Analogical learning consists \\nof learning new knowledge about an entity by transferring it from a similar entity , and by testing it43, 44. 9 \\n Abductive learning  consists of hypothesizing causes based on observed effect s45. Conceptual clustering  \\nconsists of classifying a set of objects into different classes/concepts and in learning a description of each \\nsuch class/concept46. Quantitative discovery  consists in discovering a quantitative law relating values of \\nvariables characterizing an object or a system47. Reinforcement learning  consists of improving  agent’s \\nknowledge  based on feedback from the environment48. Genetic algorithm -based learning  consi sts of \\nevolving a population of individuals over a sequence of generations, based on models of heredity and \\nevolution49. \\nThese learning methods may be used to extend the ontology of an agent with new concepts or facts , or \\nto learn and refine its reasoning rules. Many of the se methods  are complementary in terms of the input \\nfrom which the agent learns, the a priori knowledge the agent needs in order to learn, the inferences \\nmade  during learning, what is actually learned, and the effect of learning on agent’s  performane . For \\ninstance, in the case of empirical inductive learning from examples, in which the primary type of inference is induction , the input may consist of many (positive and/or negative) examples  of some concept C, the \\nknowledge base usually conta ins only a small amount of knowledge  related to the input, and the goal is \\nto learn a description of the concept C in the form of an inductive generalization of the positive examples \\nwhich does not cover the negative examples. This description extends or r efines the knowledge base and \\nimprove s the competence of the agent in solving a larger class of problems and in  mak ing fewer mistakes.  \\nIn the case of explanation -based learning, in which the primary type of inference is deduction, the input \\nmay consist of only one example  of a concept C, the knowledge base should contain complete knowledge \\nabout the input , and the goal is to learn an operational description of C  in the form of a deductive \\ngeneralization of the input example. This description is a reorganization of some knowledge pieces from the knowledge base and improve s the problem solving efficiency of the agent.  \\nBoth analogical learning and abductive learning extend the knowledge base with new pieces of knowledge \\nand usually i mprove the competence of the agent.  In the case of analogical learning, the input may consist \\nof a new entity I , the knowledge base should contain an entity S which is similar to I , and the goal is to \\nlearn new knowledge about the input I  by transferring it from the known entity S.  In abductive learning, \\nthe input may be a fact F , the knowledge base should contain knowledge related to the input  and the goal \\nis to learn a new piece of knowledge  that would explain  the input.  \\nEach learning method, used separately, has  limited applicability because it requires a special type of input \\nand background knowledge , and it learns a specific type of knowledge.  On the other hand, the \\ncomplementary nature of these requirements and results naturally suggests that b y properly integrating \\nthese single -strategy methods, one can obtain a synergistic effect in which different strategies mutually \\nsupport each other and compensate for each other\\'s weaknesses. A large number of multistrategy learning agents that integrate v arious learning strategies have been developed\\n50, 51.  Some integrate \\nempirical induction with explanation -based learning, while others integrate symbolic and neural net \\nlearning, or deduction with abduction and analogy, or quantitative and qualitative dis covery, or symbolic \\nand genetic algorithm -based learning, and so on.  10 \\n A type of multistrategy learning is that employed by the Disciple agents that can be trained how to \\nperform their tasks, in ways that are similar to how one would train students or appre ntices, through \\nspecific examples and explanations, and through the supervision and correction of their behavior2, 52. For \\ninstance, an expert may show a Disciple  agent the reasoning tree from Fig.  5. Each question/answer pair \\nfollowing a problem represent s the explanation of why that problem is decomposed in the indicated way. \\nBut understanding and generalizing these reasoning steps and their explanations, the agent learns general \\nreasoning rules. It then analogically applies these rules to solve similar p roblems, such as, “Assess whether \\nChina  will be a global leader in solar  power within the next decade.”  The expert analyses agent’s reasoning \\nand characterizes each step as correct or incorrect, also helping the agent in understand ing its mistakes. \\nEach of  these reasoning steps represents a positive or a negative example for a previously learned rule \\nwhich is appropriately generalized to cover the positive example or specialized to no longer cover the \\nnegative example.  As the agent learns new rules and conc epts from the expert, their interaction evolves \\nfrom a teacher- student interaction, toward an interaction where they both collaborate in problem -\\nsolving. This process is based on mixed-initiative problem solving53, where the expert solves the more \\ncreative  parts of the problem and the agent solves the routine ones and learns from the creative solutions , \\nintegrated learning and teaching , where the expert helps the agent to learn (e.g., by providing \\nrepresentative examples, hints , and explanations), and the a gent helps the expert to teach it (e.g., by \\nasking relevant questions) , and, as already mentioned, multistrategy learning , where the agent integrates \\ncomplementary strategies, such as learning from examples, learning from explanations, and learning by analogy, to learn general concepts and rules.  \\nNATURAL LANGUAGE , SPEECH,  AND VISION  \\nThe perceptual processing module in Fig.  1 summarizes agent’s capabilities to process natural language, \\nspeech, and visual inputs. All are very easy for humans and very difficult for automated agents.  \\nWhen an agent receives  input in natural language, it has to understand it, that is, to build an internal \\nrepresentation of its meaning, which can then be used by the problem solving engine. This process, \\nhowever, is very difficult f or several reasons. Natural language is ambiguous at all levels: morphology, \\nsyntax, semantics, and discourse\\n54, 55. Just by hearing a common word such as “run” we cannot say  \\nwhether  it is a noun or a verb. The  WordNet semantic dictionary56 gives  16 senses  for the noun \\ninterpretation and 41 senses for the verb interpretation.  What does the word  “diamond ” mean ? Does it \\nmean  the mineral consisting of nearly pure carbon in crystalline  form ? Does it mean  a gem or other piece \\ncut from this mineral?  Does it mean  a lozenge -shaped plane figure ( ♦)? Does it mean  the playing field in \\nBaseball? Therefore the meaning of a word needs to be interpreted in the context of its s urroundi ng \\nwords. But sentences themselves may be ambiguous. What does “Visiting relatives can be  boring” mean? \\nDoes it mean that the act of visiting relatives can be boring? M aybe it means that the relatives who visit \\nus can be boring. Consider also the possible meanings of the following sentence: “She told the man that she hated to run alone.”  Therefore the meanings of individual sentences need  themselves  to be \\ninterpreted in the context of the paragraphs that contain them. This is also necessary because of \\nadditional complexities of natural language, such as, the use of paraphrases (where the same m eaning \\nmay be expressed by different sentences), ellipses (the u se of sentences that appear ill- formed because \\nthey are incomplete , which requires the extraction of the missing parts from previous sentences ), and 11 \\n references (where entities are referred by pronouns, such as “it” or “they,” without giving their names). \\nBut even considering larger paragraphs may not be enough for understanding their meaning, unless the \\nagent has a large amount of knowledge about the domain of discourse.  \\nAs illustrated in Fig.  757, understanding a natural language sentence (such as “Tarzan kissed Jane .”) \\ninvolves a sequence of stages , including part-of-speech disambiguation, parsing (which analyzes the \\nsyntactic structure of the input sentence and produces a parse tree that iden tifies its syntactic \\ncomponents, such as “noun phrase” and “verb phrase” ), semantic interpretation  (which produces an \\ninternal representation of the meaning of the sentence) , and contextual/ world knowledge interpretation  \\n(where the internal representation is extended with world knowledge from the knowledge base, such as \\n“Tarzan loves Jane,”  to produce a more complete and accurate understanding of the meaning of the \\nsentence).  The resulting structure represents agent’s understanding of the meaning of the input sentence \\nwhich may further be used to answer a  question, translate the sentence into a different language, or \\nunderstand a story.   \\nThe above  stages are based on various t ypes of grammars which specify the rules for well- formed \\nexpressions, and are augmented with semantic interpretations. Early natural language understanding \\nsystems were based on manually -defined grammars and were limited in their coverage of a given natural \\nlanguage. Therefore successful systems were developed for restricted areas of discourse, such as airline \\nreservation or question -answering in a specific domain .  \\nThe availability of large language corpora on the world -wide web has had a very significant impact on the \\nfield of natural language processing, both in terms of the methods and techniques involved (which are \\nnow mainly based on probability and statistics), and in terms of its applications. In these approaches, prior probabilities are associated w ith specific words, and with the rules of the grammar. This allows one to \\ndetermine the probability distribution of various meanings of an ambiguous word or sentence, and to \\ndetermine the most lik ely meaning in a given context\\n11, 58. \\nA type of very successful application of statistical natural language processing and concept  learning is \\nclassifying a text into one of several categories. Examples of such applications include  identifying the \\nlanguage of a text, identifying whether a product review is positive  or negative, or whether an email \\nmessage is spam or non -spam, with recognition accuracy in the range of 98% -99% and, in some ca ses, \\nexceeding 99.9%1, p. 866.  \\nIn information retrieval, a user specifies a query in natural language and the agent has to retu rn the most \\nrelevant documents from a given knowledge repository, such as the World Wide Web. In question answering, the user desires an answer to its question, rather than a document. Because of the huge \\namount of information on the web , which is likely t o contain many answers to a question , and in many \\nforms, an agent has to understand what the question is about (topic) , and what the user is interested in \\n(focus). It can then  provide a simple template  for the expected answer rather than trying all the pos sible \\nparaphrases  based on  deep natural language understanding. This is because it is very likely that the simple \\nanswer template will match some text on the web.  12 \\n As mentioned several times , an intelligen t agent needs a huge amount of knowledge in its knowledge \\nbase , which is very difficult to define. With the progress made in statistical natural language processing, \\nsome of this knowledge, such as parts of the ontology ( i.e., concepts, instances, relations hips – see Fig. 2) \\ncan be automatically learned.  \\nFinally, another important area of natural language processing is automatic translation from one natural \\nlanguage into another. All translation systems use some models  of the source and target languages. \\nClassical approach es attempt to understand the source language text, translate it into an interlingua \\nrepresentation, and then generate sentences in the target language from that representation. In statistical \\napproaches, translations are generated on the bas is of statistical models whose parameters are derived \\nfrom the analysis of bilingual parallel text corpora.  \\nSpeech recognition consists in identifying the spoken words from their acoustic signals, and is difficult \\nbecause these signals are both ambiguous and noisy . Therefore the most successful approaches are also \\nbased on statistical methods. Both machine trans lation  and speech recognition  are among the biggest  \\nsuccesses of artificial intelligence , and are part of many applications59. \\nResearch on vision c oncerns the development of algorithms allow ing an agent to extract information from \\nits environment to recognize and manipulate  objects , and to navigate60. Many algorithms have been \\ndeveloped that detect the edges, texture, and surfaces  of objects , and segment an image in to its main \\ncomponents. However, r ecognizing component objects in a scene , or understanding the scene , remain \\nvery difficult problem s. \\nACTION PROCESSING AND ROBOTICS  \\nThe action processing module in Fig.  1 corresponds to the  agent’s actions upon that environment aimed \\nat realiz ing the goals or tasks for which it was designed . Such an action could be the generation of a n \\nanswer  to a question, the solution of an input problem, the manipulation of an object, or the navigation \\nto a new positio n. Since most of these actions have already been addressed in the above section s, here \\nwe only address object manipulation and navigation, which are the main concern of the robotics area61.  \\nOne may distinguish between three main types of robots: (1) manip ulators which are robot ic arms \\nattached to their workspace, such as those used in car assembly and painting; (2) mobile robots with \\nwheels, legs, or wings , used to move objects around, such as the unmanned air vehicles for surveillance, \\ncrop -spraying, or m ilitary operations, or the  autonomous underwater vehicles; and (3) mobile \\nmanipulators that combine mobility with manipulation to accomplish more complex tasks.  A challenging \\nproblem in robotics is localization and mapping, which consists in finding out wh ere things are and \\nbuilding a map  of the environment . Another challenging problem is path planning from one point in space \\nto another point , which  may involve compliant motion, where the robot moves while maintaining physical \\ncontact with an object  (e.g., an obstacle, a box it  pushe s, or a screw it inserts ). \\nRobots have many applications in industry (e.g., for part  assembly or painting), agriculture (e.g., as special \\nmachines), transportation (e.g., autonomous vehicles), health care (e.g., as devices for su rgery), \\nhazardous en vironments (e.g., for clearing minefields or cleaning up nuclear waste), space exploration, 13 \\n and entertainment. They can provide personal services (e.g., vacuum cleaning), or can act as human \\naugmentation devices (e.g., by providing addi tional force to facilitate walking or arm movement).  \\nCONCLUSION  \\nThe main goal of Artificial Intelligence is to develop computational agents that exhibit the characteristics \\nwe associate with intelligence in human behavior. Such an agent  has an internal rep resentation of its \\nexternal environment  which  is at their basis of its  reasoning abilities . In general, an agent  solves  complex  \\nreal- world problems  by using large  amount s of knowledge  and heuristic  methods . It is highly desirable \\nthat the agent’s knowledge  and reasoning are understandable to humans, and the agent is  able to explain \\nits behavior, what decisions it is making , and why.  The agent may reason with data items that are more \\nor less in contradiction  with one another, and  may provide some solution without having all the relevant \\ndata . The agent should be able to communicate with its users , ideally in natural language, and it may \\ncontinuously learn .  \\nWhy are i ntelligent agents important?  Because  humans have limitations that agents may alleviate , such  \\nas limited attention span, ability to analyze only a small number of alternatives at a time , or memory for \\nthe details that is not affected by stress, fatigue or time constraints . Humans are slow, sloppy, forg etful, \\nimplicit, and subjective. B ut they have  common sense and intuition, and may find creative solutions in \\nnew situations. By  contrast, agents  are fast, rigorous, precise, explicit, and objective . But they lack \\ncommon sense and the ability to deal with novel  situations62, 63. Humans and agents may thus  engage in \\nmixed -initiative reasoning  that takes advantage of their complementary strengths and reasoning styles.  \\nAs such, i ntelligent agents enable us to do our tasks better, and help us in cop ing with the increasing \\nchallenges of globalization and th e rapid evolution toward the knowledge economies64. \\nREFERENCES  \\n1. Russell SJ, Norvig P.  Artificial Int elligence: A Modern Approach , Prentice -Hall, 2010.  \\n2. Tecuci  G. Building Intelligent Agents: An Apprenticeship Multistrategy Learning Theory, Methodology,  \\nTool and Case Studies , Academic Press, San Diego , 1998.  \\n3. Turing A.  Computing machinery and intelligence . Mind  1950 , 59:433 -460. \\n4. Samuel AL.  Some studies in machine learning using the game of checkers . IBM Journal of Research \\nand Development  1959, 3:210 -229. \\n5. Robinson JA.  A machine -oriented logic based on the resolution principle . JACM  1965 , 12:23 -41. \\n6. Buchanan BG, Sutherland GL, Feigenbaum EA, Heuristic DENDRAL: A program for generating \\nexplanatory hypotheses in organic chemistry. In Meltzer B, Michie D, Swan M, ed. Machine \\nIntelligence  1969, 4:209 -254.  \\n7. Bucha nan BG, Shortliffe EH.  Rule Based Expert Systems . Reading, MA: Addison -Wesley, 1984.  \\n8. Anderson JR.  The Architecture of Cognition . Harvard University Press, 1983.  \\n9. Laird J , Newell A, Rosenbloom PS.  SOAR: An architecture for general intelligence . Artificial Intelligence \\nJournal  1987 , 33:1- 64.   14 \\n 10. Tecuci G . DISCIPLE: A Theory, Methodology and System for Learning Expert Knowledge . Thèse de \\nDocteur en Science.  University of Paris- South, 1988 . \\n11. Manning C, Schutze H.  Foundations of Statistical Natural Language Processing . MIT Press, 1999.  \\n12. Rich E, Knight  K. Artificial Intelligence . McGraw -Hill, 1993.  \\n13. Brachman RJ, Levesque H J., ed.  Readings in Knowledge Representation. Mor gan Kaufmann, San \\nMateo, CA , 1985 . \\n14. Brachman R J, Levesque  H. Knowledge Representation and Reasoning. Morgan Kaufman , San \\nFrancisco, CA,  2004.  \\n15. McCarthy  J. Progra ms with common sense. In Minsky ML, ed.  Semantic Information Processing . MIT \\nPress, Cambridge, MA , 1968 403-418.  \\n16. Kowalski R. Logic for Problem Solving. Elsevier , North -Holland, Amsterdam, London, New York , 1979 . \\n17. Genesereth MR, Nilsson N J. Logical Foundations of Artificial Intelligence. Morgan Kaufmann , San \\nMateo, CA,  1987. \\n18. Waterman D, Hayes -Roth  F. Pattern -Directed Inference Systems. New York,  Academic Press , 1978 . \\n19. Brownston L , Farrell R, Kant E, Martin  N. Programming Expert Systems in OPS5: An Introduction to \\nRule -Based Programming. Reading, Addison -Wesley , MA , 1985.  \\n20. Quillian M R. Semantic memory . In Minsky M, ed. Semantic Information Processing . Cambridge, Mass , \\nMIT Press , 1968 227 -270.  \\n21. Minsky  M. A framework for rep resenting knowledge. In Winston P H, ed.  The Psychology of Computer \\nVision . McGraw -Hill, New York , 1975  211-277.  \\n22. Bobrow DG, Winograd  T. An overview of KRL, a knowledge representation language. Cognitive Science \\n1977, 1:3 -46. \\n23. Sowa J F. Knowledge Representation: Logical, Philosophical, and Computational Foundations. \\nBrooks/C ole, Pacific Grove, CA , 1984 . \\n24. Brachman RJ, Schmolze JG.  An overview of the KL -ONE knowledge representation system. Cognitive \\nScience  1985, 9: 171-216.  \\n25. Lenat  DB, Guha R V. Building Large Knowledge -Based Systems: Representation and Inference in the \\nCYC Project. Addison -Wesley, Reading, Massach usetts, 1990 . \\n26. Pearl J. Causality: Models, Reasoning, and Inference. Cambridge University Press, New York, 2009.  \\n27. Cohen LJ.  The Probable and the Provable . Clarendon Press, Oxford, 1977.  \\n28. Cohen LJ.  An Introduction to the Philosophy of Induction and Probability . Clarendon Press, Oxford, \\n1989.  \\n29. Shafer G.  A Mathematical Theory of Evidence . Princeton University Press, Princeton, NJ, 1976.  \\n30. Zadeh  L. The Role of Fuzzy Logic in the Management of Uncerta inty in Expert Systems . Fuzzy Sets and \\nSystems  1983 , 11:199 - 227.  \\n31. Schum DA.  The Evidential Foundations of Probabilistic Reasoning . Northwestern University Press, \\n1994, 2001.  \\n32. OWL 2 Web Ontology Language , http://www.w3.org/TR/owl2 -overview/ (accesse d August 14 2011)  15 \\n 33. Campbel l MS, Hoane AJ, Hsu F -H. Deep Blue . Artificial Intelligence Journal 2002, 134: 57-83. \\n34. Leake D B. Case -Based Reasoning: Experiences, Lessons and Future Directions. MIT Press, 1996.  \\n35. Nilsson NJ.  Problem Solving Methods in Artificial Intelligence . McGraw -Hill, New York, NY, 1971.  \\n36. Mitchell T M. Version Spaces: An Approach to Concept Learning. Doctoral Dissertation . Stanford \\nUniversity , 1978.  \\n37. Michalski R S. A Theory and Methodology of I nductive Learning. In Michalski R S, Carbonell J G, Mitchell  \\nTM, ed. Machine Learning: An Artificial Intelligence Approach, Vol. 1. Tioga Publish ing Co,  1983, 83-\\n129. \\n38. Quinlan JR. Induction of decision trees . Machine Learning 1986, 1: 81–106.  \\n39. Mitchell TM.  Machine Learning.  McGraw -Hill, 1997.  \\n40. Hearst M A, Dumais ST, Osman E, Platt J,  Scholkopf  B. Support vector machines . IEEE Intelligent \\nSystems  1998 , 13:18 -28. \\n41. Mitchell TM , Keller RM, Kedar- Cabelli S T. Explanation -based generalization: a unifying view . Machine \\nLearning 1986 , 1:47-80. \\n42. DeJong G, Mooney  R. Explanation –based learning: an alternative view . Machine Learning  1986,  1:145-\\n176.  \\n43. Winston P H. Learning and reasoning by analogy . Communications of the ACM  1980 , 23:689 -703.  \\n44. Gentner  D. Structure mapping: a theoretical framework for analogy. Cognitive Science  1983 , 7:155-\\n170.  \\n45. Josephson  J, Josephson  S. Abductive Inference . Cambridge University Press , 1994 . \\n46. Fisher D H. Knowledge acquisition via incremental conceptual clustering . Machine Learning  1987,  \\n2:139-172.  \\n47. Langley P, Simon HA, Bradshow GL, Zytkow J M. Scientific Discovery: Computational Explorations of \\nthe Creative Processes. MIT Press, Cambridge, MA , 1987 . \\n48. Kaelbling LP, Littman ML, Moore AV . Reinforcement learning: a survey . Journal of AI  Research  1996 , \\n4:237 -285. Online journal at http://www.cs.washington.edu/research/jair/ -home.html  \\n49. DeJong K. Evolutionary Computation: Theory and Practice . MIT Press , 2006.  \\n50. Tecuci  G. Plausible justification trees: a framework for the deep and dynamic integration  of learning \\nstrategies . Machine Learning Journal  1993 , 11: 237- 261. \\n51. Michalski RS., Tecuci  G., ed.  Machine Learning: A Multistrategy Approach . Morgan Kaufmann \\nPublishers, San Mateo, CA , 1994.  \\n52. Tecuci G, Boicu M, Boicu C, Marcu D, Stanescu B, Barbule scu M.  The Disciple -RKF learning and \\nreasoning agent . Computational Intelligence  2005, 21: 462-479.  \\n53. Tecuci G, Boicu M, Cox M T. Seven aspects of mixed -initiative reasoning: an introduction to the special \\nissue on mixed -initiative assistants . AI Magazine  2007, 28:11-18. \\n54. Tufiş  D, Ion  R, Ide  N. Fine -grained word sense disambiguation based on parallel corpora, word \\nalignment, word clustering and aligned wordnets . In Proceedings of the 20th International Conference \\non Computational Linguistic s, COLING2004,  Geneva, 2004 1312 -1318.  16 \\n 55. Tufiş  D. Algorithms and data design issues for basic nlp tools . In Nirenburg S, ed. Language Engineering \\nfor Lesser- Studied Languages, IOS Press, NATO Science for Peace and Security Series -  D: Informat ion \\nand Communication Sec urity 2009, 21:3 -50. \\n56. http://wordnetweb.princeton.edu/perl/webwn  (accessed October 1 2011)  \\n57. Luger GF, Artificial Intelligence: Structures and Strategies for Complex Problem Solving . 6th ed, P earson \\nEducation , Inc, 2009.  \\n58. Jurafsky  D, Martin  JH. Speech and Language Processing.  Prentice Hall, 2008.  \\n59. Huang XD, Acero A, Hon H . Spoken Language Processing.  Prentice Hall, 2001.  \\n60. Forsyth D, Ponce J.  Computer Vision: A Modern Approach . Prentice Hall, 2002.  \\n61. Bekey G . Robotics: State of the Art and Future Challenges . Imperial College Press, 2008.  \\n62. Turoff M.  Design of Interactive Systems . In Emergency Management Information Systems Tutorial . \\nThe Hawaii International Conference on Sys tem Sciences, HICSS -40. Hawaii, 2007.  \\n63. Phillips -Wren G, Jain LC, Nakamatsu K, Howlett R J., ed.  Advances in Intelligent Decision Technologies , \\nSIST 4 . Springer -Verlag , Berlin Heidelberg, 2010.  \\n64. Toward Knowledge Societies, http://unesdoc.unesco.org/images/0014/001418/141843e.pdf  \\n(accessed October 1 2011)  \\n  17 \\n  \\n \\n \\n Figure 1. Main components of a knowledge -based agent . Problem \\nSolving Engine\\nLearning \\nEnginePerceptual \\nProcessing\\nAction \\nProcessingKnowledge Base ReasoningAgentEnvironmentsensory\\ninput\\naction\\noutput\\n \\nFigure 2. A situation and its representation.  Rule\\n∀x,y,z∈object, (on x y) & (on y z) \\uf0e0(on x z)oncup1 book1ontable1cup book table\\ninstance ofobject\\nsubclass ofOntology\\nvessel furniture publication\\n \\nFigure 3. Bayesian network  showing the causal relationships between events and their prior \\nprobabilities.  Burglary at Bob’s house \\nP(B)= 0.002, P (¬B)= 0.998Earthquake\\nP(E)=0.005, P(¬E)=0.995\\nJohn calls owner\\nP(J|H)= 0.93, P( ¬J|H)= 0.07\\nP(J|¬H)= 0.06, P(¬J|¬H)= 0.94Mary calls owner\\nP(M|H)= 0.65, P(¬ M|H)= 0.35\\nP(M|¬H)= 0.01, P(¬M|¬H)= 0.99House alarm set off\\nP(H|B,E )=0.96, P(¬H|B,E )=0.04\\nP(H|B,¬ E)=0.93, P(¬H|B,¬ E)=0.07\\nP(H|¬B,E )=0.21, P(¬H|¬B,E )=0.79\\nP(H|¬B,¬ E)=0.01, P(¬H| ¬B,¬ E)=0.99causes\\ncauses18 \\n  \\n  \\n \\n \\n \\n  \\nFigure 4. Problem solving as search.  S45S3I\\nS4 S6\\nGO3 O6 O4\\nO5\\nO1\\nO3\\nO2S47O719 \\n Figure 5. Problem solving through reduction and synthesis.  \\n \\n    \\n \\n  \\n     \\n20 \\n  \\nFigure 7.  Stages in understanding a natural language sentence (from Luger FG, Artificial Intelligence, 2009: 624).  Input: Tarzan kissed Jane.\\nparse tree: sentence\\nverb phrase\\nnoun phrasenoun phrase\\nverb noun noun\\nTarzan Jane kissed\\ninternal representation:\\nperson: tarzan person: jane\\nkiss agent object\\ninstrument lipsexpanded representation:\\nperson: tarzan person: jane\\nkiss agent object\\ninstrument lipslove experiencer object\\njungle location locationpet: cheetah possessParsing\\nSemantic interpretationContextual/world \\nknowledge interpretation\\nTo:\\nquestion answerer,\\ndata query handler, \\ntranslator, etc.\\nView publication stats'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "astra_token = os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")\n",
        "astra_db_id = os.getenv(\"ASTRA_DB_ID\")\n",
        "cassio.init(token=astra_token, database_id=astra_db_id)"
      ],
      "metadata": {
        "id": "uXagqNTg5Am1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai_key=os.getenv(\"OPENAI_API_KEY\")\n",
        "llm = OpenAI(openai_api_key=openai_key)\n",
        "embedding = OpenAIEmbeddings(openai_api_key=openai_key,model=\"text-embedding-ada-002\")"
      ],
      "metadata": {
        "id": "Al6YXU7t5Aq5"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create your LangChain vector store ... backed by Astra DB!"
      ],
      "metadata": {
        "id": "VVUIVgFGBzfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store = Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"qa_mini_demo\",\n",
        "    session=None,\n",
        "    keyspace=None,\n",
        ")"
      ],
      "metadata": {
        "id": "-4eaTaCo5Avb"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "# We need to split the text using Character Text Split such that it sshould not increse token size\n",
        "text_splitter = CharacterTextSplitter(\n",
        "    separator = \"\\n\",\n",
        "    chunk_size = 800,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        ")\n",
        "texts = text_splitter.split_text(raw_text)"
      ],
      "metadata": {
        "id": "uAFMDzN-5Ay0"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset into the vector store"
      ],
      "metadata": {
        "id": "nJ44fD-bCIQX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "astra_vector_store.add_texts(texts)\n",
        "\n",
        "print(\"Inserted %i headlines.\" % len(texts))\n",
        "\n",
        "astra_vector_index = VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WhUxDAW5A2J",
        "outputId": "48bb4b8d-4446-4187-be96-b0292688389d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inserted 93 headlines.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_question = True\n",
        "while True:\n",
        "    if first_question:\n",
        "        query_text = input(\"\\nEnter your question (or type 'quit' to exit): \").strip()\n",
        "    else:\n",
        "        query_text = input(\"\\nWhat's your next question (or type 'quit' to exit): \").strip()\n",
        "\n",
        "    if query_text.lower() == \"quit\":\n",
        "        break\n",
        "\n",
        "    if query_text == \"\":\n",
        "        continue\n",
        "\n",
        "    first_question = False\n",
        "\n",
        "    print(\"\\nQUESTION: \\\"%s\\\"\" % query_text)\n",
        "    answer = astra_vector_index.query(query_text, llm=llm).strip()\n",
        "    print(\"ANSWER: \\\"%s\\\"\\n\" % answer)\n",
        "\n",
        "    print(\"FIRST DOCUMENTS BY RELEVANCE:\")\n",
        "    for doc, score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "        print(\"    [%0.4f] \\\"%s ...\\\"\" % (score, doc.page_content[:84]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoX00QJ1DjEX",
        "outputId": "c2da874e-6b28-44e3-eb63-b25fec085f49"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Enter your question (or type 'quit' to exit): what is KNOWLEDGE ACQUISITION AND LEARNING\n",
            "\n",
            "QUESTION: \"what is KNOWLEDGE ACQUISITION AND LEARNING\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER: \"KNOWLEDGE ACQUISITION AND LEARNING is the process of enabling an intelligent agent to acquire or learn knowledge from a user, input data, or its own problem-solving experience. This process improves the competence and efficiency of the agent in solving a broader range of problems and making fewer mistakes.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [0.9239] \"logic , mak ing it suitable  for developing knowledge -based agents that assist can  ...\"\n",
            "    [0.9238] \"logic , mak ing it suitable  for developing knowledge -based agents that assist can  ...\"\n",
            "    [0.9030] \"Journal  1987 , 33:1- 64.   14 \n",
            " 10. Tecuci G . DISCIPLE: A Theory, Methodology and  ...\"\n",
            "    [0.9030] \"Journal  1987 , 33:1- 64.   14 \n",
            " 10. Tecuci G . DISCIPLE: A Theory, Methodology and  ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): what is NATURAL LANGUAGE, SPEECH, AND VISION???\n",
            "\n",
            "QUESTION: \"what is NATURAL LANGUAGE, SPEECH, AND VISION???\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSWER: \"NATURAL LANGUAGE, SPEECH, AND VISION are different forms of input that are difficult for automated agents to process, but are easy for humans. They include features such as grammar, syntax, semantics, and discourse. These inputs can be processed by a perceptual processing module in an agent, but the process of understanding them is difficult and often ambiguous.\"\n",
            "\n",
            "FIRST DOCUMENTS BY RELEVANCE:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    [0.9154] \"speech, and visual inputs. All are very easy for humans and very difficult for autom ...\"\n",
            "    [0.9153] \"speech, and visual inputs. All are very easy for humans and very difficult for autom ...\"\n",
            "    [0.9092] \"integrated learning and teaching , where the expert helps the agent to learn (e.g.,  ...\"\n",
            "    [0.9092] \"integrated learning and teaching , where the expert helps the agent to learn (e.g.,  ...\"\n",
            "\n",
            "What's your next question (or type 'quit' to exit): quit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZlQHOhnjCKW0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MBYQGSzICKTn"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}